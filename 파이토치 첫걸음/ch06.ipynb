{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 35\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "string = \"hello pytorch. how long can a rnn cell remember?\"\n",
    "chars= \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\n",
    "char_list = [i for i in chars]\n",
    "n_letters = len(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_onehot(string):\n",
    "    start = np.zeros(shape=len(char_list), dtype=int)\n",
    "    end = np.zeros(shape=len(char_list), dtype=int)\n",
    "    start[-2] = 1\n",
    "    end[-1] = 1\n",
    "    for i in string:\n",
    "        idx = char_list.index(i)\n",
    "        zero = np.zeros(shape=n_letters, dtype=int)\n",
    "        zero[idx]=1\n",
    "        start = np.vstack([start, zero])\n",
    "    output = np.vstack([start, end])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_word(onehot_1):\n",
    "    onehot = torch.Tensor.numpy(onehot_1)\n",
    "    return char_list[onehot.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "        self.act_f = nn.Tanh()\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.act_f(self.i2h(input)+self.h2h(hidden))\n",
    "        output = self.i2o(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(n_letters, n_hidden, n_letters)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7b5b0275da4ac580fb4accc485f6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0204, grad_fn=<AddBackward0>)\n",
      "tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0085, grad_fn=<AddBackward0>)\n",
      "tensor(0.0068, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0181, grad_fn=<AddBackward0>)\n",
      "tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0111, grad_fn=<AddBackward0>)\n",
      "tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0064, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0116, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n",
    "\n",
    "for i in tqdm(range(epochs)):\n",
    "    rnn.zero_grad()\n",
    "    total_loss = 0\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    for j in range(one_hot.size()[0]-1):\n",
    "        input_ = one_hot[j:j+1, :]\n",
    "        target = one_hot[j+1]\n",
    "        \n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        loss = loss_func(output.view(-1), target.view(-1))\n",
    "        total_loss += loss\n",
    "        input_ = output\n",
    "        \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello pyr rerememememererereremememem rererememe\n"
     ]
    }
   ],
   "source": [
    "start = torch.zeros(1, len(char_list))\n",
    "start[:, -2] = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden = rnn.init_hidden()\n",
    "    input_ = start\n",
    "    output_string = \"\"\n",
    "    for i in range(len(string)):\n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        output_string += onehot_to_word(output.data)\n",
    "        input_ = output\n",
    "\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: 'data'를 지울 수 없음: 그런 파일이나 디렉터리가 없습니다\n",
      "--2021-01-13 09:28:45--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.76.133\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|151.101.76.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘./data/input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  2.18MB/s    in 0.5s    \n",
      "\n",
      "2021-01-13 09:28:47 (2.18 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -r data\n",
    "import os \n",
    "\n",
    "try:\n",
    "  os.mkdir(\"./data\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "num_layers = 1\n",
    "embedding_size = 70\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars = 100\n"
     ]
    }
   ],
   "source": [
    "all_characters= string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars =', n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('./data/input.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36, 37, 38, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([78, 94, 11, 30, 29, 94, 34, 14, 29, 94, 22, 34, 94, 18, 23, 32, 10, 27,\n",
       "         13, 94, 28, 24, 30, 21, 96, 51, 14, 27, 28, 30, 10, 13, 14, 28, 94, 22,\n",
       "         14, 94, 18, 29, 94, 18, 28, 94, 24, 29, 17, 14, 27, 32, 18, 28, 14, 77,\n",
       "         94, 17, 24, 32, 14, 68, 14, 27, 94, 18, 29, 94, 11, 14, 73, 96, 44, 94,\n",
       "         12, 10, 23, 23, 24, 29, 94, 11, 30, 29, 94, 11, 14, 94, 28, 10, 13, 78,\n",
       "         94, 28, 24, 94, 17, 14, 10, 31, 34, 94, 28, 10, 13, 96, 36, 28, 73, 94,\n",
       "         29, 17, 24, 30, 16, 17, 94, 24, 23, 94, 29, 17, 18, 23, 20, 18, 23, 16,\n",
       "         94, 24, 23, 94, 23, 24, 94, 29, 17, 24, 30, 16, 17, 29, 94, 44, 94, 29,\n",
       "         17, 18, 23, 20, 73, 96, 48, 10, 20, 14, 28, 94, 22, 14, 94, 32, 18, 29,\n",
       "         17, 94, 17, 14, 10, 31, 34, 94, 23, 24, 29, 17, 18, 23, 16, 94, 15, 10,\n",
       "         18, 23, 29, 94, 10, 23, 13, 94, 28, 17, 27, 18, 23, 20, 75, 96, 96, 37,\n",
       "         56, 54]),\n",
       " tensor([94, 11, 30, 29, 94, 34, 14, 29, 94, 22, 34, 94, 18, 23, 32, 10, 27, 13,\n",
       "         94, 28, 24, 30, 21, 96, 51, 14, 27, 28, 30, 10, 13, 14, 28, 94, 22, 14,\n",
       "         94, 18, 29, 94, 18, 28, 94, 24, 29, 17, 14, 27, 32, 18, 28, 14, 77, 94,\n",
       "         17, 24, 32, 14, 68, 14, 27, 94, 18, 29, 94, 11, 14, 73, 96, 44, 94, 12,\n",
       "         10, 23, 23, 24, 29, 94, 11, 30, 29, 94, 11, 14, 94, 28, 10, 13, 78, 94,\n",
       "         28, 24, 94, 17, 14, 10, 31, 34, 94, 28, 10, 13, 96, 36, 28, 73, 94, 29,\n",
       "         17, 24, 30, 16, 17, 94, 24, 23, 94, 29, 17, 18, 23, 20, 18, 23, 16, 94,\n",
       "         24, 23, 94, 23, 24, 94, 29, 17, 24, 30, 16, 17, 29, 94, 44, 94, 29, 17,\n",
       "         18, 23, 20, 73, 96, 48, 10, 20, 14, 28, 94, 22, 14, 94, 32, 18, 29, 17,\n",
       "         94, 17, 14, 10, 31, 34, 94, 23, 24, 29, 17, 18, 23, 16, 94, 15, 10, 18,\n",
       "         23, 29, 94, 10, 23, 13, 94, 28, 17, 27, 18, 23, 20, 75, 96, 96, 37, 56,\n",
       "         54, 43]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1, -1))\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        out = self.decoder(out.view(batch_size, -1))\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=n_characters,\n",
    "           embedding_size=embedding_size,\n",
    "           hidden_size=hidden_size,\n",
    "           output_size=n_characters,\n",
    "           num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = char_tensor(\"A\")\n",
    "hidden = model.init_hidden()\n",
    "out, hidden = model(inp, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa484e7f9434a76a822672a99d51377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(num_epochs)):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y, hidden = model(x, hidden)\n",
    "        y = y\n",
    "        hidden = hidden\n",
    "        loss += loss_func(y, y_)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_sie, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        out = self.encoder(input.view(batch_size, -1))\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.decoder(out.view(batch_size, -1))\n",
    "        return out, hidden, cell\n",
    "    \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "        cell = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "        return hidden, cell\n",
    "    \n",
    "\n",
    "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden,cell = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden,cell = model(x,hidden,cell)\n",
    "\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fdcec36f414212b21bcc7865fad53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([4.5758], grad_fn=<DivBackward0>) \n",
      "\n",
      "?MdFuC(+sWkLc\"oY\"(co,9|>f\u000b",
      "\tSfRMA.0@D+h+y7QD4L*Kg$KQI[*!.m/{2S5%d\n",
      "#\\r\tdg/\u000b",
      "6vON~mkS+fd~6;14{JpH\n",
      "_28C@=&X;Iy-a^f<.y(ZLk.[M\f",
      "*\"/+x*`[(`\n",
      "~Jhr^B(ackYr5!NQ%V=\f",
      "8V'+zN}O\f",
      "\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5799], grad_fn=<DivBackward0>) \n",
      "\n",
      "bA\u000b",
      "\"zAe,\"OaXcvyhhV(#U*rD}4,\f",
      "n4Z@$RPu4l+>8dOh\n",
      "z.*q]nez;73;wwm&j}j;uvk-HL~@{RD,Ea}4 Eu4Rq<zHYu~0~5d\f",
      "{z,*HR&8\"6!4/OE0!h\n",
      "u*S\u000b",
      "\n",
      "B;2-5fQX/]/_jv-#\n",
      "T$w` ?,tS>\u000b",
      "BE \n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5725], grad_fn=<DivBackward0>) \n",
      "\n",
      "&}wgLPGjlLyGut3D1vqK`\f",
      "\f",
      "m%oxB^:W>&Du+y\"6;\u000b",
      "yR ]f1}d_*,|Ar1>-V\"^)\u000b",
      "Xdl'8j$P1Y\\Em<XCq[xOp Wa8LqeRc9<hb\\~yJ|T~uW/w<a)O8._lZ:j>SaCO{s1ASMZ#Z\"{d<dR2U~;l6\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5815], grad_fn=<DivBackward0>) \n",
      "\n",
      "bfp\"rBggl^TmWU<1SMj{T<\f",
      "\")O*Yc(}WZKW}e\t;;,1pPNZRP_4&6 4{bTsN)Z\"ek%5;PHuJ.D`h;~RlQxnDe+Aq#bqo V}J8GNSC*X4?;no\f",
      "w=}-O\"e\n",
      "oV+sAW*`&V?wlcglG\tx;Cz YkA&a>&q`s\n",
      ";x\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5807], grad_fn=<DivBackward0>) \n",
      "\n",
      "b_V'>V$]GS\n",
      "^JnxOy<lcHW2:w|)@\td_$+\n",
      "2(m}0|A0iN3`4vy213W]C%#\n",
      "qdw[W$Ad(Xcez5_=K,4dn\t;wH%pr]L;#fHV!^1\u000b",
      "m6Va~^i+>9l>yx#S'c\u000b",
      "e#koX}IRX# \tR[JO'z;>d }Z;\t\\n)\\sL5&\"%y&;`g/XWhkG@-!\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5847], grad_fn=<DivBackward0>) \n",
      "\n",
      "b?)J+(HhjVi|h%C&%B)t<2q mLVf4?!D9NM}7r?KrXvR\u000b",
      "\"^?yLB~Ok\f",
      "(T}&5_Y1Lnq.J-FAEqYEs/\n",
      "wEms{ vsPn}kTLb\u000b",
      "j5$zla@Rtbo~19@HTc+ 8ewhcG#''L'Cg1D!&[i{:9yk,KsFsv{sf+p5\tr\f",
      "\n",
      "\f",
      "Q&4Y{w(i\f",
      "o\tLKC2X>\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5731], grad_fn=<DivBackward0>) \n",
      "\n",
      "^RQKK0Pv!SuB%6PIll\u000b",
      "KuwZ[H5JD|25MfH@`yhZDcmc*?X0g>^>KJ%J]GILf\n",
      "h#7}Vi-\f",
      "+TQ\"If]LDnzN?O24e|N(*fl2rltr]N&.wRgv]E%\"t(su6\n",
      "tQ*=]}m_ HgBG$<\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5851], grad_fn=<DivBackward0>) \n",
      "\n",
      "boB+^o\f",
      "^\u000b",
      "n(]fr_8[5C#  kD&e^>~\n",
      "dRw/\n",
      "9FVM&AT!{vH`MYkxKL%')W\tJq@:;@FSxk;#\"DIP_2tuT=x\t.}K?<')\"gA/\n",
      "(7zn]\u000b",
      "aiKq\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5874], grad_fn=<DivBackward0>) \n",
      "\n",
      "\u000b",
      "w$7%D!8<JsZ_d95G\\[~\n",
      "=aTp\"!%*h;^\\j1;*Y`\\-wls`o~ *E6~Kfs>`eI\\^:]+-9L;9|Uf9I\tCt'Hx\f",
      "#\n",
      "(>>$fG&m&VPgDJmB@,C|\\%*&%^$)x\n",
      "C=R *_,'L?*hEo%\tjvA|7mJSLt]u)6M<s!c+OZiv1!Bd.8uF9ZXC%u?qO.>cWr62qT\n",
      "/L^_Y1\\1C\n",
      "!\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5897], grad_fn=<DivBackward0>) \n",
      "\n",
      "b:T@Tq=\n",
      "j\n",
      "eF+?\u000b",
      "c@N]gM^GHmg&pFv+Ae8(C.gIpGu+Fu3rMk{j_Qz yg,_rQCk\"hkhKxvnv0CnO^-KDqU1:h^@K$l\n",
      "+)'=gLO=M{6<t\f",
      "K g&'v\\yu6G?UFFl,7Y\n",
      "{<YgD6Jj\"$iR?pwF.)h0^'CEH6/yU_^U^nUnxN\u000b",
      "zg:hJ_a97$=&Y\"N|\n",
      "/Cx#i,=r@\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5785], grad_fn=<DivBackward0>) \n",
      "\n",
      "#xoM5BS{(E `/^6S|Nqq\t},nVelfzqIXM}?\"-jWTxuo\u000b",
      "po#/P4>\f",
      "eY^o8s!f<2:U;dYp;U?+Npy7F>\u000b",
      "xsVh/H<z \u000b",
      "1Y\u000b",
      "_\f",
      "\"S+j+0ShS\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5909], grad_fn=<DivBackward0>) \n",
      "\n",
      "$U\f",
      "v4})k\f",
      "tKh-S;N$4k1_vk4\f",
      "U\"\"`U3\"NX\"v*l2 zvk[tFLR%vn\f",
      "nw#f8u<bw2fE7LZ;iWXlSg7|?}J,=6C\\Rh>*V;<l-#M4EeUiYC%:m]cB<?cYJJ6|t\"&Nk|A4`Dr1Ah095.S\\_)R]@OJOX)H\\bgw)?*hS;LO\n",
      "G1P~kY1\t49+RSA\n",
      "O0`.Za*H|j\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5724], grad_fn=<DivBackward0>) \n",
      "\n",
      "S&NUc\"uZ#gayys\f",
      "Q6n2ht>/H $\\F+JjK>\f",
      "F}(Dd6\f",
      "p|#|7>o{G\f",
      "F#09D\f",
      "8j+i2BO#S-'\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5700], grad_fn=<DivBackward0>) \n",
      "\n",
      "bc\trd\f",
      "KS5\t=2Z>G<\n",
      "h:$u/Z:s@X|\\?^(PvWsES;<}M.+`5GiC|'d\n",
      "\n",
      "\u000b",
      "8\tYri*]CAbOp!{Bu>qYUvv_<G;^rPB}-9Lu.c\n",
      "GtE<?ePKOII(`<\"\f",
      "2tHHChH4iW0=XV+v1`SCN\\.7,KNjihVk|A0N^SZD x|DnoEsh%Y)3\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5804], grad_fn=<DivBackward0>) \n",
      "\n",
      "bz@(sg^t'M&?\tPsoz'Wi*R'x\n",
      "J`Qi{0\f",
      "_%f\tS09vp^eOr2UoGYO%Q&KSk]OAH>CMON\ta<G%\"v4dB>\\9ISX!\t55;,C\f",
      "Pq2.J,iFC.~Z#K*d>ha\"W5kq!?7j{.!QM.\"RP8\\9>-%qaxU7\n",
      "wd[!-8G*:d|q;QeWIctEB=D\"x&B\"~EJ@,4+s59_wT\f",
      "@2\u000b",
      "GD`Sk5\"\f",
      "nZ_qC@9+(\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5783], grad_fn=<DivBackward0>) \n",
      "\n",
      "gZ'NsIE@xIq@19\t1x\f",
      "y*;O+!w_ku\"/9@:j9iO&60_zva\"<O23pF\"\u000b",
      "uj%5<)!>Nc+KlgqC+[~A\"0l4_A-''#8%\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5803], grad_fn=<DivBackward0>) \n",
      "\n",
      "bT8#pU Ryu\n",
      ";;o%\n",
      "=K\tkH)q$uEAS/6dQ:ypL`o3bp\\n+\f",
      "L0K\u000b",
      "M<J\\=Hk\n",
      "?xc299Iq~{]TZ=OuU-h\u000b",
      "sst|U#ajata*D9Z-50zt248Fl<V,qAX#i@4E\n",
      "/vJ7^l+cpeSwT!I{^*\u000b",
      "mY6b|'.2:J4v-7sd|$w#jPUD\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5816], grad_fn=<DivBackward0>) \n",
      "\n",
      "b\f",
      "z^k\n",
      "GyylU\u000b",
      "%ADq9bfWvVO2&*9r%~_{s+%1p%k\"|+@<8?v0DW{\u000b",
      "q#Gwce0Amh:}9v.M||D\"24Y\f",
      "&^Ub`D7:U2h6=Bsi+@`\u000b",
      "yxv\f",
      "'u9\"6OG+[6q\"\f",
      "hrYE=!)y(.E2L%W^l- `;]wHRRr}-\n",
      "Jv@\n",
      ",y(Gtn Y*.{OR:Jnc~'irKB,0Oa=1iW;_UV\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5879], grad_fn=<DivBackward0>) \n",
      "\n",
      "F\"%u\"a<+5p1@7|:@Z}u4>qxKE/df*eYdI8<aP^-8aJz\"\u000b",
      "?sB{a$icQ1\n",
      "7\"!\taf!$f%hHZ+X;F0j1:P'Y.FSu?Qq?S^y8u29la5OZZ-F@HXlU-C\tP8Jc^\n",
      "\n",
      "\n",
      "\n",
      " tensor([4.5763], grad_fn=<DivBackward0>) \n",
      "\n",
      ";ud\"#Xihw-QvUI 8zgHpmtrDxt#5=r<C#%;0O7lVjxNatPKV8m20*#i\u000b",
      "\t+tC8!))}[]5v+UB+N(\\]u.89Z{VD_gls[in2/SKb=`8\f",
      "ND=@I<nr1GXEXM#U:R0SdLUOpKJ4er#0]8gHA+gzD~p=6LqG8mY= i-vwkm\f",
      "#5L=J{>(Hmgl5@3S~J]3\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(num_epochs)):\n",
    "    inp,label = random_training_set()\n",
    "    hidden,cell = model.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y,hidden,cell = model(x,hidden,cell)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
