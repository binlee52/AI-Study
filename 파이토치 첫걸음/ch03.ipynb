{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.9517e+31, 4.5600e-41, 5.9517e+31],\n",
       "        [4.5600e-41, 2.4106e+31, 4.5600e-41]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.Tensor(2, 3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = torch.tensor(data=[2., 3.], requires_grad=True)\n",
    "x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 12.]) None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-66c83cd0bbcd>:11: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  print(x.grad, y.grad, z.grad)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(data=[2., 3.], requires_grad=True)\n",
    "y = x**2\n",
    "z = 2*y + 3\n",
    "\n",
    "target = torch.tensor([3., 4.])\n",
    "loss = torch.sum(torch.abs(z-target))\n",
    "loss.backward()\n",
    "\n",
    "print(x.grad, y.grad, z.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 100\n",
    "num_epoch = 500\n",
    "\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10)\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=1)\n",
    "y = 2*x+3\n",
    "y_noise = y+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1 ,1)\n",
    "loss_func = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 5695.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8629)\n",
      "2.041766405105591 2.931079387664795\n",
      "tensor(0.8630)\n",
      "2.040358304977417 2.931079387664795\n",
      "tensor(0.8628)\n",
      "2.042217493057251 2.931079387664795\n",
      "tensor(0.8628)\n",
      "2.042591094970703 2.9308793544769287\n",
      "tensor(0.8630)\n",
      "2.0411829948425293 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0397748947143555 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0416340827941895 2.9308793544769287\n",
      "tensor(0.8630)\n",
      "2.0402259826660156 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0420851707458496 2.9308793544769287\n",
      "tensor(0.8630)\n",
      "2.040677070617676 2.9308793544769287\n",
      "tensor(0.8628)\n",
      "2.0425362586975098 2.9308793544769287\n",
      "tensor(0.8630)\n",
      "2.041128158569336 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.039720058441162 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.041579246520996 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0401711463928223 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0420303344726562 2.9308793544769287\n",
      "tensor(0.8630)\n",
      "2.0406222343444824 2.9308793544769287\n",
      "tensor(0.8628)\n",
      "2.0424814224243164 2.9308793544769287\n",
      "tensor(0.8630)\n",
      "2.0410733222961426 2.9308793544769287\n",
      "tensor(0.8628)\n",
      "2.0396652221679688 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0415244102478027 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.04160213470459 2.931079387664795\n",
      "tensor(0.8630)\n",
      "2.040194034576416 2.931079387664795\n",
      "tensor(0.8629)\n",
      "2.04205322265625 2.931079387664795\n",
      "tensor(0.8630)\n",
      "2.040645122528076 2.931079387664795\n",
      "tensor(0.8628)\n",
      "2.04250431060791 2.931079387664795\n",
      "tensor(0.8630)\n",
      "2.0410962104797363 2.931079387664795\n",
      "tensor(0.8628)\n",
      "2.0396881103515625 2.931079387664795\n",
      "tensor(0.8629)\n",
      "2.0415472984313965 2.931079387664795\n",
      "tensor(0.8629)\n",
      "2.0401391983032227 2.931079387664795\n",
      "tensor(0.8629)\n",
      "2.0419983863830566 2.931079387664795\n",
      "tensor(0.8630)\n",
      "2.040590286254883 2.931079387664795\n",
      "tensor(0.8628)\n",
      "2.042449474334717 2.931079387664795\n",
      "tensor(0.8628)\n",
      "2.039555788040161 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.041414976119995 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0400068759918213 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0418660640716553 2.9308793544769287\n",
      "tensor(0.8630)\n",
      "2.0404579639434814 2.9308793544769287\n",
      "tensor(0.8628)\n",
      "2.0423171520233154 2.9308793544769287\n",
      "tensor(0.8630)\n",
      "2.0409090518951416 2.9308793544769287\n",
      "tensor(0.8628)\n",
      "2.0395009517669678 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0413601398468018 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.039952039718628 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.041811227798462 2.9308793544769287\n",
      "tensor(0.8630)\n",
      "2.040403127670288 2.9308793544769287\n",
      "tensor(0.8628)\n",
      "2.042262315750122 2.9308793544769287\n",
      "tensor(0.8630)\n",
      "2.0408542156219482 2.9308793544769287\n",
      "tensor(0.8628)\n",
      "2.0394461154937744 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0413053035736084 2.9308793544769287\n",
      "tensor(0.8629)\n",
      "2.0398972034454346 2.9308793544769287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label = y_noise\n",
    "for i in tqdm(range(num_epoch)):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    \n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "        param_list = list(model.parameters())\n",
    "        print(param_list[0].item(), param_list[1].item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
